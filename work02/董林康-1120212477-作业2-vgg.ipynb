{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Any, cast, Dict, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from ..transforms._presets import ImageClassification # ImageClassification是用来做图像分类的\n",
    "from ..utils import _log_api_usage_once # _log_api_usage_once是用来记录api使用情况的\n",
    "from ._api import register_model, Weights, WeightsEnum # Weights是用来存储权重的，WeightsEnum是用来存储权重的枚举类\n",
    "from ._meta import _IMAGENET_CATEGORIES # _IMAGENET_CATEGORIES是用来存储imagenet的类别的\n",
    "from ._utils import _ovewrite_named_param, handle_legacy_interface # _ovewrite_named_param是用来重写命名参数的，handle_legacy_interface是用来处理旧的接口的"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存储所有变量的列表\n",
    "\n",
    "方便更好的查看本文件中的所有变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [ # __all__是用来存储所有的变量的列表\n",
    "    \"VGG\", # VGG class\n",
    "    \"VGG11_Weights\", # VGG11 weights\n",
    "    \"VGG11_BN_Weights\", # VGG11 BN weights (Batch Normalization)\n",
    "    \"VGG13_Weights\", # VGG13 weights\n",
    "    \"VGG13_BN_Weights\", # VGG13 BN weights (Batch Normalization)\n",
    "    \"VGG16_Weights\", # VGG16 weights\n",
    "    \"VGG16_BN_Weights\", # VGG16 BN weights (Batch Normalization)\n",
    "    \"VGG19_Weights\", # VGG19 weights\n",
    "    \"VGG19_BN_Weights\", # VGG19 BN weights (Batch Normalization)\n",
    "    \"vgg11\", # VGG11 model\n",
    "    \"vgg11_bn\", # VGG11 BN model (Batch Normalization)\n",
    "    \"vgg13\", # VGG13 model\n",
    "    \"vgg13_bn\", # VGG13 BN model (Batch Normalization)\n",
    "    \"vgg16\", # VGG16 model\n",
    "    \"vgg16_bn\", # VGG16 BN model (Batch Normalization)\n",
    "    \"vgg19\", # VGG19 model\n",
    "    \"vgg19_bn\", # VGG19 BN model (Batch Normalization)\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG model \n",
    "\n",
    "在这个部分程序中定义了VGG模型的结构，用于提取特征部分的`make_layers`函数，网络结构配置字典`cfg`，以及VGG构建模型`_vgg`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VGG model\n",
    "class VGG(nn.Module):\n",
    "    def __init__(\n",
    "        self, features: nn.Module, num_classes: int = 1000, init_weights: bool = True, dropout: float = 0.5\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        _log_api_usage_once(self) # Log API usage\n",
    "        self.features = features # Features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) # Average Pooling\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        ) # 分类器中采用了两个全连接层，两个Dropout层，一个ReLU激活函数\n",
    "\n",
    "\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d): # 如果是卷积层，使用Kaiming初始化\n",
    "                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\") # weight使用Kaiming初始化\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0) # bias使用常数初始化\n",
    "\n",
    "                elif isinstance(m, nn.BatchNorm2d): # 如果是BatchNorm2d层，使用常数初始化\n",
    "                    nn.init.constant_(m.weight, 1) # weight使用常数初始化\n",
    "                    nn.init.constant_(m.bias, 0) # bias使用常数初始化\n",
    "\n",
    "                elif isinstance(m, nn.Linear): # 如果是全连接层，使用normal初始化\n",
    "                    nn.init.normal_(m.weight, 0, 0.01) # weight使用normal初始化\n",
    "                    nn.init.constant_(m.bias, 0) # bias使用常数初始化\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x) # 特征提取\n",
    "        x = self.avgpool(x) # 平均池化\n",
    "        x = torch.flatten(x, 1) # 展平\n",
    "        x = self.classifier(x) # 分类\n",
    "        return x\n",
    "\n",
    "\n",
    "# make_layers函数用于构建VGG的特征提取部分，即前面的卷积层和池化层\n",
    "# @param cfg: 网络结构配置\n",
    "# @param batch_norm: 是否使用Batch Normalization\n",
    "# @return: VGG的特征提取部分\n",
    "def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\n",
    "    layers: List[nn.Module] = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == \"M\":\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            v = cast(int, v)\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# 全局变量，用于存储VGG的网络结构配置\n",
    "cfgs: Dict[str, List[Union[str, int]]] = {\n",
    "    \"A\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"B\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "    \"E\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"],\n",
    "}\n",
    "\n",
    "\n",
    "# _vgg函数用于构建VGG模型\n",
    "# @param cfg: 网络结构配置\n",
    "# @param batch_norm: 是否使用Batch Normalization\n",
    "# @param weights: 预训练模型的权重\n",
    "# @param progress: 是否显示下载进度条\n",
    "# @param kwargs: 其他参数\n",
    "def _vgg(cfg: str, batch_norm: bool, weights: Optional[WeightsEnum], progress: bool, **kwargs: Any) -> VGG:\n",
    "    if weights is not None:\n",
    "        kwargs[\"init_weights\"] = False\n",
    "        if weights.meta[\"categories\"] is not None:\n",
    "            _ovewrite_named_param(kwargs, \"num_classes\", len(weights.meta[\"categories\"]))\n",
    "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\n",
    "    if weights is not None:\n",
    "        model.load_state_dict(weights.get_state_dict(progress=progress))\n",
    "    return model\n",
    "\n",
    "# COMMON_META是一个字典，用于存储模型基本信息\n",
    "_COMMON_META = {\n",
    "    \"min_size\": (32, 32), # 输入图像的最小尺寸\n",
    "    \"categories\": _IMAGENET_CATEGORIES, # 分类类别\n",
    "    \"recipe\": \"https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg\", # 训练方法\n",
    "    \"_docs\": \"\"\"These weights were trained from scratch by using a simplified training recipe.\"\"\", # 训练方法\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载各模型的预训练权重\n",
    "\n",
    "其代码模式几乎一致，拿其中一共来举例并做注释：\n",
    "\n",
    "```python\n",
    "class VGG11_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg11-8a719046.pth\", # 权重文件的下载地址\n",
    "        transforms=partial(ImageClassification, crop_size=224), # 预训练权重的数据预处理方式，这里的crop在原论文中也提到了，裁剪的大小为224\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 132863336, # 参数量为133M\n",
    "            \"_metrics\": { # 在ImageNet-1K上的精度\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 69.020, # top-1精度\n",
    "                    \"acc@5\": 88.628, # top-5精度\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 7.609, # 计算量\n",
    "            \"_file_size\": 506.84, # 权重文件大小\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VGG11_Weights是一个枚举类，用于存储VGG11的预训练模型\n",
    "class VGG11_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg11-8a719046.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 132863336,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 69.020,\n",
    "                    \"acc@5\": 88.628,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 7.609,\n",
    "            \"_file_size\": 506.84,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "# 枚举类，用于存储VGG11_BN的预训练模型\n",
    "class VGG11_BN_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 132868840,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 70.370,\n",
    "                    \"acc@5\": 89.810,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 7.609,\n",
    "            \"_file_size\": 506.881,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "# 枚举类，用于存储VGG13的预训练模型\n",
    "class VGG13_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg13-19584684.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 133047848,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 69.928,\n",
    "                    \"acc@5\": 89.246,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 11.308,\n",
    "            \"_file_size\": 507.545,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "# 枚举类，用于存储VGG13_BN的预训练模型\n",
    "class VGG13_BN_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg13_bn-abd245e5.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 133053736,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 71.586,\n",
    "                    \"acc@5\": 90.374,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 11.308,\n",
    "            \"_file_size\": 507.59,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "# 枚举类，用于存储VGG16的预训练模型\n",
    "class VGG16_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg16-397923af.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 138357544,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 71.592,\n",
    "                    \"acc@5\": 90.382,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 15.47,\n",
    "            \"_file_size\": 527.796,\n",
    "        },\n",
    "    )\n",
    "    IMAGENET1K_FEATURES = Weights(\n",
    "        # Weights ported from https://github.com/amdegroot/ssd.pytorch/\n",
    "        url=\"https://download.pytorch.org/models/vgg16_features-amdegroot-88682ab5.pth\",\n",
    "        transforms=partial(\n",
    "            ImageClassification,\n",
    "            crop_size=224,\n",
    "            mean=(0.48235, 0.45882, 0.40784),\n",
    "            std=(1.0 / 255.0, 1.0 / 255.0, 1.0 / 255.0),\n",
    "        ),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 138357544,\n",
    "            \"categories\": None,\n",
    "            \"recipe\": \"https://github.com/amdegroot/ssd.pytorch#training-ssd\",\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": float(\"nan\"),\n",
    "                    \"acc@5\": float(\"nan\"),\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 15.47,\n",
    "            \"_file_size\": 527.802,\n",
    "            \"_docs\": \"\"\"\n",
    "                These weights can't be used for classification because they are missing values in the `classifier`\n",
    "                module. Only the `features` module has valid values and can be used for feature extraction. The weights\n",
    "                were trained using the original input standardization method as described in the paper.\n",
    "            \"\"\",\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "# 枚举类，用于存储VGG16_BN的预训练模型\n",
    "class VGG16_BN_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 138365992,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 73.360,\n",
    "                    \"acc@5\": 91.516,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 15.47,\n",
    "            \"_file_size\": 527.866,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "# 枚举类，用于存储VGG19的预训练模型\n",
    "class VGG19_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 143667240,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 72.376,\n",
    "                    \"acc@5\": 90.876,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 19.632,\n",
    "            \"_file_size\": 548.051,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "# 枚举类，用于存储VGG19_BN的预训练模型\n",
    "class VGG19_BN_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 143678248,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 74.218,\n",
    "                    \"acc@5\": 91.842,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 19.632,\n",
    "            \"_file_size\": 548.143,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注册模型\n",
    "\n",
    "下面的代码是将各个模型注册到`torchvision.models`中，方便调用，现在对其中一个模型代码做逐行注释：\n",
    "\n",
    "```python\n",
    "@register_model() # 注册模型\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG19_BN_Weights.IMAGENET1K_V1)) # 处理旧版本的接口\n",
    "def vgg19_bn(*, weights: Optional[VGG19_BN_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-19_BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG19_BN_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG19_BN_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.VGG19_BN_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG19_BN_Weights.verify(weights) # 验证权重是否合法\n",
    "\n",
    "    return _vgg(\"E\", True, weights, progress, **kwargs) # 返回VGG模型\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@register_model() \n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG11_Weights.IMAGENET1K_V1))\n",
    "def vgg11(*, weights: Optional[VGG11_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-11 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG11_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG11_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.VGG11_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG11_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"A\", False, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG11_BN_Weights.IMAGENET1K_V1))\n",
    "def vgg11_bn(*, weights: Optional[VGG11_BN_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-11-BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG11_BN_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG11_BN_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.VGG11_BN_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG11_BN_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"A\", True, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG13_Weights.IMAGENET1K_V1))\n",
    "def vgg13(*, weights: Optional[VGG13_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-13 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG13_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG13_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.VGG13_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG13_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"B\", False, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG13_BN_Weights.IMAGENET1K_V1))\n",
    "def vgg13_bn(*, weights: Optional[VGG13_BN_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-13-BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG13_BN_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG13_BN_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.VGG13_BN_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG13_BN_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"B\", True, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG16_Weights.IMAGENET1K_V1))\n",
    "def vgg16(*, weights: Optional[VGG16_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-16 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG16_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG16_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.VGG16_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG16_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"D\", False, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG16_BN_Weights.IMAGENET1K_V1))\n",
    "def vgg16_bn(*, weights: Optional[VGG16_BN_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-16-BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG16_BN_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG16_BN_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.VGG16_BN_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG16_BN_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"D\", True, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG19_Weights.IMAGENET1K_V1))\n",
    "def vgg19(*, weights: Optional[VGG19_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-19 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG19_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG19_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.VGG19_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG19_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"E\", False, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG19_BN_Weights.IMAGENET1K_V1))\n",
    "def vgg19_bn(*, weights: Optional[VGG19_BN_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-19_BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG19_BN_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG19_BN_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.VGG19_BN_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG19_BN_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"E\", True, weights, progress, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
