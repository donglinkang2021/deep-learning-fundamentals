{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评估\n",
    "\n",
    "评估一下之前的LeNet和AlexNet模型，看看效果如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from models import LeNet,AlexNet # 注：LeNet的数据不用transform，AlexNet的数据要transform\n",
    "import torchvision.transforms as transforms\n",
    "train_labels = torch.load('../data/train_labels.pt')\n",
    "train_data = torch.load('../data/train_data.pt')\n",
    "test_labels = torch.load('../data/test_labels.pt')\n",
    "test_data = torch.load('../data/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_train_and_test_acc(model):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(train_data.to(device))\n",
    "        y_pred = torch.softmax(y_pred, dim=1)  # dim=1表示对每一行进行softmax\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        accuracy = torch.sum(y_pred == train_labels.to(device)).item() / len(train_labels)\n",
    "    print(f\"Train Accuracy: {accuracy:.2f}\")\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(test_data.to(device))\n",
    "        y_pred = torch.softmax(y_pred, dim=1)\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        accuracy = torch.sum(y_pred == test_labels.to(device)).item() / len(test_labels)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.55\n",
      "Test Accuracy: 0.49\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "# 在测试集上评估模型的准确率\n",
    "model.load_state_dict(torch.load(\"model_LeNet.pth\"))\n",
    "eval_train_and_test_acc(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Resuming from checkpoint..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model = AlexNet()\n",
    "print('==> Resuming from checkpoint..')\n",
    "assert os.path.isdir('checkpoint_colab'), 'Error: no checkpoint_colab directory found!'\n",
    "checkpoint = torch.load('./checkpoint_colab/ckpt.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['net'])\n",
    "best_acc = checkpoint['acc']\n",
    "start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_epoch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 用原数据评估是错的，因为我们是在归一化的数据上训练的\n",
    "# model = AlexNet()\n",
    "# model.load_state_dict(checkpoint['net'])\n",
    "# eval_train_and_test_acc(model)\n",
    "# Train Accuracy: 0.35\n",
    "# Test Accuracy: 0.35\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# 只需要归一化\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 加载 CIFAR10 数据集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,shuffle=False, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 50000 train images: 72 %\n",
      "Accuracy of the network on the 10000 test images: 69 %\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 50000 train images: %d %%' % (100 * correct / total))\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([ 3.1295,  3.3430,  1.9316,  4.0670, 10.7482,  4.0784,  4.8922,  3.4887,\n",
       "         3.6127,  2.9611,  2.5348,  2.1729,  2.1153,  6.0943,  1.8651, 11.7545]),\n",
       "indices=tensor([7, 5, 0, 0, 8, 4, 7, 0, 3, 3, 3, 8, 5, 5, 4, 7]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(outputs.data, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
