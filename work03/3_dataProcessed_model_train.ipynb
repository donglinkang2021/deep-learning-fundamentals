{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JELQmxpMDpbG",
        "outputId": "5c829067-be5b-488a-c304-013e0da6d23b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 12 10:47:33 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBfST4z9UL6E"
      },
      "source": [
        "# 数据增广\n",
        "\n",
        "> 在开始之前记得把`models.py`扔进来\n",
        "\n",
        "由于之前的0到3的小demo中最终得到的准确率结果都不好，前面测试中最好的模型只是0.62（AlexNet），所以这里考虑是数据量太少了的问题来重新进行数据增广，增加数据量。\n",
        "\n",
        "\n",
        "## ask chatgpt\n",
        "\n",
        "> pytorch CIFAR10任务，我有train_data（50000，3，32，32）,train_labels（50000）,test_data（10000，3，32，32）,test_labels（10000）四个tensor，你可以告诉我如何使用transform来进行数据增广吗，比如重塑宽高、翻转、张量化、规范化\n",
        "\n",
        "当我们进行深度学习任务时，使用数据增强技术可以提高模型的泛化能力。在 PyTorch 中，我们可以使用 transforms 模块来对数据进行增强。下面是一个使用 transforms 对 CIFAR10 数据集进行数据增强的示例：\n",
        "\n",
        "在下面的代码中，transform_train 定义了训练数据的增强方式，包括随机水平翻转、随机裁剪、张量化、规范化等步骤。transform_test 定义了测试数据的增强方式，只包括张量化和规范化。\n",
        "\n",
        "通过 transforms.Compose 将多个 transform 组合起来，形成一个 transform 序列。在加载数据集时，将这个 transform 序列传递给 transform 参数即可实现数据增强。\n",
        "\n",
        "使用 transforms.RandomCrop() 可以进行裁剪操作，使用 transforms.RandomHorizontalFlip() 可以进行随机水平翻转。对于张量化和规范化，使用 transforms.ToTensor() 将数据转换成 tensor 格式，并使用 transforms.Normalize() 将数据规范化到均值为 0、标准差为 1。\n",
        "\n",
        "在上面的代码中，我们定义了训练数据和测试数据的 transform 不同，因为测试数据不需要进行数据增强，只需要进行归一化即可。\n",
        "\n",
        "最后，使用 DataLoader 加载数据集时，可以设置 batch_size 和 shuffle 等参数，进行批处理和打乱数据的操作。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5GEyAWHUL6I",
        "outputId": "002f2eed-3d14-4da0-aa94-7c168a1f4246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12989298.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 定义 transform，包括随机水平翻转、随机裁剪、归一化\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 只需要归一化\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 加载 CIFAR10 数据集\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some test here\n",
        "trainset.data[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aP2_in8KYJQ",
        "outputId": "7e9d9376-2ca5-4e05-e2e8-5c5f1312653b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        if batch_idx == 0:\n",
        "            whole_test_inputs = inputs\n",
        "            whole_test_targets = targets\n",
        "        else:\n",
        "            whole_test_inputs = torch.cat((whole_test_inputs, inputs), dim=0)\n",
        "            whole_test_targets = torch.cat((whole_test_targets, targets), dim=0)\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        if batch_idx == 0:\n",
        "            whole_train_inputs = inputs\n",
        "            whole_train_targets = targets\n",
        "        else:\n",
        "            whole_train_inputs = torch.cat((whole_train_inputs, inputs), dim=0)\n",
        "            whole_train_targets = torch.cat((whole_train_targets, targets), dim=0)\n",
        "\n",
        "whole_train_inputs.shape,whole_test_inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kwZZxvLKnvN",
        "outputId": "dc61f25b-862c-4a79-b77e-c3fb56e29bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50000, 3, 32, 32]), torch.Size([10000, 3, 32, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nypsOlb8LvFF",
        "outputId": "b63fa115-8de1-483c-d0f3-329ae820655f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         ...,\n",
              "         [ 0.6706,  0.5529,  0.4588,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [ 0.6706,  0.4510,  0.3176,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [ 0.5843,  0.3882,  0.2314,  ..., -1.0000, -1.0000, -1.0000]],\n",
              "\n",
              "        [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         ...,\n",
              "         [ 0.3647,  0.2314,  0.1294,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [ 0.3725,  0.1294, -0.0039,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [ 0.2863,  0.0667, -0.0824,  ..., -1.0000, -1.0000, -1.0000]],\n",
              "\n",
              "        [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         ...,\n",
              "         [ 0.1922,  0.0510, -0.0824,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [ 0.1843, -0.0588, -0.2000,  ..., -1.0000, -1.0000, -1.0000],\n",
              "         [ 0.0980, -0.1294, -0.2471,  ..., -1.0000, -1.0000, -1.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvgUx5lDUL6K"
      },
      "source": [
        "## 定义模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkEe0-o9Uv-4",
        "outputId": "b137715d-4c7d-4a20-9e0d-48a8f6b5348b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok7mNWWAUL6K",
        "outputId": "1316d39c-5e94-4145-88ed-f6eabed1723c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "AlexNet                                  [10, 10]                  --\n",
              "├─Sequential: 1-1                        [10, 256, 1, 1]           --\n",
              "│    └─Conv2d: 2-1                       [10, 64, 17, 17]          1,792\n",
              "│    └─ReLU: 2-2                         [10, 64, 17, 17]          --\n",
              "│    └─MaxPool2d: 2-3                    [10, 64, 8, 8]            --\n",
              "│    └─Conv2d: 2-4                       [10, 192, 8, 8]           307,392\n",
              "│    └─ReLU: 2-5                         [10, 192, 8, 8]           --\n",
              "│    └─MaxPool2d: 2-6                    [10, 192, 3, 3]           --\n",
              "│    └─Conv2d: 2-7                       [10, 384, 3, 3]           663,936\n",
              "│    └─ReLU: 2-8                         [10, 384, 3, 3]           --\n",
              "│    └─Conv2d: 2-9                       [10, 256, 3, 3]           884,992\n",
              "│    └─ReLU: 2-10                        [10, 256, 3, 3]           --\n",
              "│    └─Conv2d: 2-11                      [10, 256, 3, 3]           590,080\n",
              "│    └─ReLU: 2-12                        [10, 256, 3, 3]           --\n",
              "│    └─MaxPool2d: 2-13                   [10, 256, 1, 1]           --\n",
              "├─Sequential: 1-2                        [10, 10]                  --\n",
              "│    └─Dropout: 2-14                     [10, 256]                 --\n",
              "│    └─Linear: 2-15                      [10, 4096]                1,052,672\n",
              "│    └─ReLU: 2-16                        [10, 4096]                --\n",
              "│    └─Dropout: 2-17                     [10, 4096]                --\n",
              "│    └─Linear: 2-18                      [10, 4096]                16,781,312\n",
              "│    └─ReLU: 2-19                        [10, 4096]                --\n",
              "│    └─Linear: 2-20                      [10, 10]                  40,970\n",
              "==========================================================================================\n",
              "Total params: 20,323,146\n",
              "Trainable params: 20,323,146\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 573.17\n",
              "==========================================================================================\n",
              "Input size (MB): 0.12\n",
              "Forward/backward pass size (MB): 3.76\n",
              "Params size (MB): 81.29\n",
              "Estimated Total Size (MB): 85.18\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from models import AlexNet\n",
        "from torchinfo import summary\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AlexNet()\n",
        "model.to(device)\n",
        "summary(model, input_size=(10, 3, 32, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGqnxgqpUL6L"
      },
      "source": [
        "## 开始训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCIBWKQWUL6L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from models import LeNet, AlexNet\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ArgumentConfig:\n",
        "    def __init__(self,\n",
        "        lr=0.001,\n",
        "        resume=False,\n",
        "        model='AlexNet',\n",
        "        epochs=20,\n",
        "        is_print=True,\n",
        "        print_every=100\n",
        "        ):\n",
        "        self.lr = lr\n",
        "        self.resume = resume\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.is_print = is_print\n",
        "        self.print_every = print_every\n",
        "\n",
        "args = ArgumentConfig()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5HYzkefXOMQ"
      },
      "outputs": [],
      "source": [
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 定义优化器\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "# 定义学习率衰减\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "# 定义 tensorboard\n",
        "writer = SummaryWriter(log_dir='runs/' + args.model)\n",
        "\n",
        "# 定义是否使用 GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 定义是否加载模型\n",
        "if args.resume:\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "# 定义训练函数\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        if batch_idx % args.print_every == 0 and args.is_print:\n",
        "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAcc: {:.3f}%'.format(\n",
        "                epoch, \n",
        "                batch_idx * len(inputs), len(trainloader.dataset),\n",
        "                100. * batch_idx / len(trainloader), loss.item(),\n",
        "                100. * correct / total\n",
        "                )\n",
        "            )\n",
        "    writer.add_scalar('Train/Loss', train_loss / (batch_idx + 1), epoch)\n",
        "    writer.add_scalar('Train/Acc', 100. * correct / total, epoch)\n",
        "\n",
        "# 定义测试函数\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    writer.add_scalar('Test/Loss', test_loss / (batch_idx + 1), epoch)\n",
        "    writer.add_scalar('Test/Acc', 100. * correct / total, epoch)\n",
        "    return 100. * correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(args.epochs):\n",
        "    train(epoch)\n",
        "    acc = test(epoch)\n",
        "    scheduler.step()\n",
        "    # 保存模型\n",
        "    state = {\n",
        "        'net': model.state_dict(),\n",
        "        'acc': acc,\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    if not os.path.isdir('checkpoint'):\n",
        "        os.mkdir('checkpoint')\n",
        "    torch.save(state, './checkpoint/ckpt.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnR9DmnTdmhD",
        "outputId": "5cb509d7-a3b8-43ef-e820-4a64b4ef710a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 [0/50000 (0%)]\tLoss: 2.301693\tAcc: 10.156%\n",
            "Epoch: 0 [12800/50000 (26%)]\tLoss: 1.888814\tAcc: 16.863%\n",
            "Epoch: 0 [25600/50000 (51%)]\tLoss: 1.896521\tAcc: 20.211%\n",
            "Epoch: 0 [38400/50000 (77%)]\tLoss: 1.834874\tAcc: 22.508%\n",
            "Epoch: 1 [0/50000 (0%)]\tLoss: 1.750635\tAcc: 39.062%\n",
            "Epoch: 1 [12800/50000 (26%)]\tLoss: 2.011476\tAcc: 33.748%\n",
            "Epoch: 1 [25600/50000 (51%)]\tLoss: 1.675899\tAcc: 35.273%\n",
            "Epoch: 1 [38400/50000 (77%)]\tLoss: 1.523618\tAcc: 36.451%\n",
            "Epoch: 2 [0/50000 (0%)]\tLoss: 1.603559\tAcc: 44.531%\n",
            "Epoch: 2 [12800/50000 (26%)]\tLoss: 1.599068\tAcc: 41.716%\n",
            "Epoch: 2 [25600/50000 (51%)]\tLoss: 1.333047\tAcc: 43.027%\n",
            "Epoch: 2 [38400/50000 (77%)]\tLoss: 1.408852\tAcc: 43.906%\n",
            "Epoch: 3 [0/50000 (0%)]\tLoss: 1.355330\tAcc: 48.438%\n",
            "Epoch: 3 [12800/50000 (26%)]\tLoss: 1.490497\tAcc: 48.476%\n",
            "Epoch: 3 [25600/50000 (51%)]\tLoss: 1.381185\tAcc: 49.347%\n",
            "Epoch: 3 [38400/50000 (77%)]\tLoss: 1.417524\tAcc: 49.450%\n",
            "Epoch: 4 [0/50000 (0%)]\tLoss: 1.394465\tAcc: 50.781%\n",
            "Epoch: 4 [12800/50000 (26%)]\tLoss: 1.400771\tAcc: 52.800%\n",
            "Epoch: 4 [25600/50000 (51%)]\tLoss: 1.540732\tAcc: 52.919%\n",
            "Epoch: 4 [38400/50000 (77%)]\tLoss: 1.359516\tAcc: 53.486%\n",
            "Epoch: 5 [0/50000 (0%)]\tLoss: 1.259965\tAcc: 55.469%\n",
            "Epoch: 5 [12800/50000 (26%)]\tLoss: 1.242973\tAcc: 54.757%\n",
            "Epoch: 5 [25600/50000 (51%)]\tLoss: 1.412276\tAcc: 55.018%\n",
            "Epoch: 5 [38400/50000 (77%)]\tLoss: 1.323334\tAcc: 55.271%\n",
            "Epoch: 6 [0/50000 (0%)]\tLoss: 1.291396\tAcc: 57.031%\n",
            "Epoch: 6 [12800/50000 (26%)]\tLoss: 1.181454\tAcc: 57.279%\n",
            "Epoch: 6 [25600/50000 (51%)]\tLoss: 1.382305\tAcc: 56.899%\n",
            "Epoch: 6 [38400/50000 (77%)]\tLoss: 1.244310\tAcc: 56.764%\n",
            "Epoch: 7 [0/50000 (0%)]\tLoss: 1.195340\tAcc: 57.812%\n",
            "Epoch: 7 [12800/50000 (26%)]\tLoss: 1.257821\tAcc: 57.952%\n",
            "Epoch: 7 [25600/50000 (51%)]\tLoss: 1.144808\tAcc: 57.882%\n",
            "Epoch: 7 [38400/50000 (77%)]\tLoss: 1.254156\tAcc: 58.178%\n",
            "Epoch: 8 [0/50000 (0%)]\tLoss: 1.064995\tAcc: 65.625%\n",
            "Epoch: 8 [12800/50000 (26%)]\tLoss: 1.119911\tAcc: 58.725%\n",
            "Epoch: 8 [25600/50000 (51%)]\tLoss: 1.160528\tAcc: 59.177%\n",
            "Epoch: 8 [38400/50000 (77%)]\tLoss: 1.238292\tAcc: 59.357%\n",
            "Epoch: 9 [0/50000 (0%)]\tLoss: 1.036012\tAcc: 62.500%\n",
            "Epoch: 9 [12800/50000 (26%)]\tLoss: 1.016916\tAcc: 60.381%\n",
            "Epoch: 9 [25600/50000 (51%)]\tLoss: 1.418146\tAcc: 60.619%\n",
            "Epoch: 9 [38400/50000 (77%)]\tLoss: 1.112238\tAcc: 60.343%\n",
            "Epoch: 10 [0/50000 (0%)]\tLoss: 1.187159\tAcc: 57.812%\n",
            "Epoch: 10 [12800/50000 (26%)]\tLoss: 1.097113\tAcc: 61.433%\n",
            "Epoch: 10 [25600/50000 (51%)]\tLoss: 1.204709\tAcc: 60.774%\n",
            "Epoch: 10 [38400/50000 (77%)]\tLoss: 1.095494\tAcc: 60.958%\n",
            "Epoch: 11 [0/50000 (0%)]\tLoss: 1.243799\tAcc: 58.594%\n",
            "Epoch: 11 [12800/50000 (26%)]\tLoss: 0.956826\tAcc: 62.291%\n",
            "Epoch: 11 [25600/50000 (51%)]\tLoss: 1.076546\tAcc: 62.049%\n",
            "Epoch: 11 [38400/50000 (77%)]\tLoss: 1.121092\tAcc: 61.999%\n",
            "Epoch: 12 [0/50000 (0%)]\tLoss: 1.120552\tAcc: 59.375%\n",
            "Epoch: 12 [12800/50000 (26%)]\tLoss: 0.964625\tAcc: 62.848%\n",
            "Epoch: 12 [25600/50000 (51%)]\tLoss: 1.100494\tAcc: 62.380%\n",
            "Epoch: 12 [38400/50000 (77%)]\tLoss: 1.056436\tAcc: 62.303%\n",
            "Epoch: 13 [0/50000 (0%)]\tLoss: 1.020159\tAcc: 60.938%\n",
            "Epoch: 13 [12800/50000 (26%)]\tLoss: 1.106502\tAcc: 62.307%\n",
            "Epoch: 13 [25600/50000 (51%)]\tLoss: 0.991724\tAcc: 62.442%\n",
            "Epoch: 13 [38400/50000 (77%)]\tLoss: 1.145902\tAcc: 62.713%\n",
            "Epoch: 14 [0/50000 (0%)]\tLoss: 1.177527\tAcc: 62.500%\n",
            "Epoch: 14 [12800/50000 (26%)]\tLoss: 1.016202\tAcc: 63.668%\n",
            "Epoch: 14 [25600/50000 (51%)]\tLoss: 1.080513\tAcc: 63.538%\n",
            "Epoch: 14 [38400/50000 (77%)]\tLoss: 1.048633\tAcc: 63.453%\n",
            "Epoch: 15 [0/50000 (0%)]\tLoss: 1.043246\tAcc: 66.406%\n",
            "Epoch: 15 [12800/50000 (26%)]\tLoss: 0.930009\tAcc: 63.877%\n",
            "Epoch: 15 [25600/50000 (51%)]\tLoss: 0.781914\tAcc: 63.600%\n",
            "Epoch: 15 [38400/50000 (77%)]\tLoss: 1.016861\tAcc: 63.479%\n",
            "Epoch: 16 [0/50000 (0%)]\tLoss: 1.032298\tAcc: 63.281%\n",
            "Epoch: 16 [12800/50000 (26%)]\tLoss: 0.948577\tAcc: 64.774%\n",
            "Epoch: 16 [25600/50000 (51%)]\tLoss: 1.032636\tAcc: 64.300%\n",
            "Epoch: 16 [38400/50000 (77%)]\tLoss: 1.090593\tAcc: 64.247%\n",
            "Epoch: 17 [0/50000 (0%)]\tLoss: 1.029852\tAcc: 62.500%\n",
            "Epoch: 17 [12800/50000 (26%)]\tLoss: 0.968473\tAcc: 64.124%\n",
            "Epoch: 17 [25600/50000 (51%)]\tLoss: 0.966740\tAcc: 64.315%\n",
            "Epoch: 17 [38400/50000 (77%)]\tLoss: 0.841477\tAcc: 64.312%\n",
            "Epoch: 18 [0/50000 (0%)]\tLoss: 0.940303\tAcc: 69.531%\n",
            "Epoch: 18 [12800/50000 (26%)]\tLoss: 0.873329\tAcc: 64.774%\n",
            "Epoch: 18 [25600/50000 (51%)]\tLoss: 1.275380\tAcc: 64.960%\n",
            "Epoch: 18 [38400/50000 (77%)]\tLoss: 1.111440\tAcc: 64.727%\n",
            "Epoch: 19 [0/50000 (0%)]\tLoss: 0.916925\tAcc: 67.188%\n",
            "Epoch: 19 [12800/50000 (26%)]\tLoss: 1.090794\tAcc: 64.596%\n",
            "Epoch: 19 [25600/50000 (51%)]\tLoss: 1.021964\tAcc: 64.758%\n",
            "Epoch: 19 [38400/50000 (77%)]\tLoss: 1.048268\tAcc: 64.732%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 在7分钟的训练之后达到了64.732%的准确率"
      ],
      "metadata": {
        "id": "gdPhGh7PHkfG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 训练训练训练"
      ],
      "metadata": {
        "id": "lmwvECp2ULhr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RqfWQcAWD1K"
      },
      "outputs": [],
      "source": [
        "# for epoch in range(args.epochs):\n",
        "#     train(epoch)\n",
        "#     acc = test(epoch)\n",
        "#     scheduler.step()\n",
        "#     # 保存模型\n",
        "#     state = {\n",
        "#         'net': model.state_dict(),\n",
        "#         'acc': acc,\n",
        "#         'epoch': epoch,\n",
        "#     }\n",
        "#     if not os.path.isdir('checkpoint'):\n",
        "#         os.mkdir('checkpoint')\n",
        "#     torch.save(state, './checkpoint/ckpt.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 在CPU上整整话了1小时45分钟2秒来跑10个epoch，好想吐槽一句果然还是没有gpu不行，哭死。\n",
        "> 在GPU上用了7分41秒来跑20个epoch，准确率达到了68.882%"
      ],
      "metadata": {
        "id": "nVaoAyq6Xp9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for epoch in range(args.epochs):\n",
        "#     train(epoch)\n",
        "#     acc = test(epoch)\n",
        "#     scheduler.step()\n",
        "#     # 保存模型\n",
        "#     state = {\n",
        "#         'net': model.state_dict(),\n",
        "#         'acc': acc,\n",
        "#         'epoch': epoch,\n",
        "#     }\n",
        "#     if not os.path.isdir('checkpoint'):\n",
        "#         os.mkdir('checkpoint')\n",
        "#     torch.save(state, './checkpoint/ckpt.pth')"
      ],
      "metadata": {
        "id": "6rEulKoZMSju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for epoch in range(args.epochs):\n",
        "#     train(epoch)\n",
        "#     acc = test(epoch)\n",
        "#     scheduler.step()\n",
        "#     # 保存模型\n",
        "#     state = {\n",
        "#         'net': model.state_dict(),\n",
        "#         'acc': acc,\n",
        "#         'epoch': epoch,\n",
        "#     }\n",
        "#     if not os.path.isdir('checkpoint'):\n",
        "#         os.mkdir('checkpoint')\n",
        "#     torch.save(state, './checkpoint/ckpt.pth')"
      ],
      "metadata": {
        "id": "dJmG-7OwToXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tensorboard可视化"
      ],
      "metadata": {
        "id": "07Pb_pCkUuYe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czAN62PSZpqR"
      },
      "outputs": [],
      "source": [
        "# %load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %tensorboard --logdir runs --port 6666"
      ],
      "metadata": {
        "id": "ewgQr2A7YYD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 查看训练集和测试集上的准确率"
      ],
      "metadata": {
        "id": "xPiZEhATIid4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        # print(inputs.shape)\n",
        "        outputs = model(inputs)\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "total,correct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLPFBZQ7i_HA",
        "outputId": "24b08346-9f0c-4dd5-a857-ec07b72a4b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 6755)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "total,correct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbG6eO-Ij0Ly",
        "outputId": "84a36f77-db5a-4581-b037-8109a0b7eba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 33480)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlLgwziljPsU",
        "outputId": "e33da74b-4e1f-4ba9-c910-8598689d3e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 5, 2, 0, 3, 0, 4, 0, 4, 1, 1, 8, 9, 9, 5, 1, 9, 6, 9, 8, 0, 8, 8, 1,\n",
              "        4, 7, 8, 9, 5, 5, 9, 3, 9, 8, 1, 4, 3, 5, 6, 9, 9, 9, 5, 8, 5, 2, 0, 7,\n",
              "        4, 8, 1, 3, 0, 4, 1, 6, 8, 3, 2, 4, 1, 0, 5, 3, 7, 3, 7, 3, 5, 6, 2, 2,\n",
              "        3, 1, 5, 0, 3, 9, 6, 9], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh5QRM1ZjSNt",
        "outputId": "07ce2bf2-fb80-4cd4-cb83-c931c1265a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 5, 2, 8, 2, 0, 2, 1, 7, 1, 1, 8, 2, 1, 5, 1, 9, 6, 9, 8, 0, 8, 9, 1,\n",
              "        4, 5, 8, 9, 3, 3, 0, 4, 9, 8, 1, 7, 6, 5, 4, 9, 1, 9, 2, 8, 3, 0, 0, 7,\n",
              "        3, 8, 1, 3, 8, 7, 0, 3, 1, 3, 2, 4, 1, 2, 5, 5, 7, 3, 7, 7, 3, 6, 4, 2,\n",
              "        7, 9, 5, 0, 6, 9, 6, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ln943Beic_M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lmwvECp2ULhr"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}